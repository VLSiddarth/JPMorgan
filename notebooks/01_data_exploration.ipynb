{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2278e11d",
   "metadata": {},
   "source": [
    "# ðŸ“Š JPMorgan European Equity Thesis â€“ Data Exploration\n",
    "\n",
    "This notebook performs **exploratory data analysis (EDA)** for the European equity thesis:\n",
    "\n",
    "- Download and inspect STOXX 600 and S&P 500 data\n",
    "- Compute returns, relative performance, and basic risk metrics\n",
    "- Demonstrate the **validator â†’ cleaner â†’ normalizer â†’ aggregator** pipeline\n",
    "- Prepare canonical datasets that feed the Streamlit dashboard\n",
    "\n",
    "> You can run this notebook standalone with just `yfinance` installed, or integrate it with the\n",
    "> full project by using the connectors and processors under `src/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51dea459",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Plotting (you can switch to Plotly if preferred)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Market data (fallback)\n",
    "import yfinance as yf\n",
    "\n",
    "# Project imports (optional â€“ work even if not yet implemented)\n",
    "try:\n",
    "    from config.settings import settings\n",
    "except Exception as exc:\n",
    "    print(\"[WARN] Could not import config.settings.Settings â€“ using defaults.\", exc)\n",
    "    settings = None\n",
    "\n",
    "# Data processors\n",
    "validator = cleaner = normalizer = aggregator = None\n",
    "try:\n",
    "    from src.data.processors.validator import validator as _validator\n",
    "    from src.data.processors.cleaner import cleaner as _cleaner\n",
    "    from src.data.processors.normalizer import normalizer as _normalizer\n",
    "    from src.data.processors.aggregator import aggregator as _aggregator\n",
    "\n",
    "    validator = _validator\n",
    "    cleaner = _cleaner\n",
    "    normalizer = _normalizer\n",
    "    aggregator = _aggregator\n",
    "except Exception as exc:\n",
    "    print(\"[WARN] Could not import validator/cleaner/normalizer/aggregator yet:\", exc)\n",
    "\n",
    "plt.style.use(\"seaborn-v0_8\")\n",
    "pd.options.display.float_format = \"{:,.4f}\".format\n",
    "\n",
    "print(\"âœ… Imports complete. pandas:\", pd.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc5239a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ------------------------------------------------------------------\n",
    "# Configuration\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "# Index tickers (Yahoo Finance)\n",
    "TICKER_STOXX_600 = \"^STOXX\"\n",
    "TICKER_SP500 = \"^GSPC\"\n",
    "\n",
    "# Date range for analysis\n",
    "end_date = datetime.today().date()\n",
    "start_date = end_date - timedelta(days=5 * 365)  # ~5 years\n",
    "\n",
    "print(f\"Using date range: {start_date} â†’ {end_date}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b58ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "            # ------------------------------------------------------------------\n",
    "            # Helper: Robust price download\n",
    "            # ------------------------------------------------------------------\n",
    "\n",
    "            def fetch_prices_yahoo(ticker: str, start: datetime, end: datetime) -> pd.Series:\n",
    "                \"\"\"Fetch adjusted close prices from Yahoo Finance as a Series.\n",
    "\n",
    "\"\n",
    "                \"Args:\n",
    "\"\n",
    "                \"    ticker: Ticker symbol (e.g. '^STOXX').\n",
    "\"\n",
    "                \"    start: Start date.\n",
    "\"\n",
    "                \"    end: End date.\n",
    "\n",
    "\"\n",
    "                \"Returns:\n",
    "\"\n",
    "                \"    Series of adjusted close prices with DateTimeIndex.\n",
    "\"\n",
    "                \"    Empty series if download fails.\n",
    "\"\n",
    "                \"\"\"\"\n",
    "\"\n",
    "                try:\n",
    "\"\n",
    "                \"    df = yf.download(ticker, start=start, end=end, progress=False)\n",
    "\"\n",
    "                \"    if df.empty:\n",
    "\"\n",
    "                \"        print(f\"[WARN] No data returned for {ticker}\")\n",
    "\"\n",
    "                \"        return pd.Series(dtype=float)\n",
    "\"\n",
    "                \"    s = df[\"Adj Close\"].rename(ticker)\n",
    "\"\n",
    "                \"    s.index = pd.to_datetime(s.index)\n",
    "\"\n",
    "                \"    return s\n",
    "\"\n",
    "                \"except Exception as exc:\n",
    "\"\n",
    "                \"    print(f\"[ERROR] Failed to download {ticker}: {exc}\")\n",
    "\"\n",
    "                \"    return pd.Series(dtype=float)\n",
    "\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d53a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 1ï¸âƒ£ Download STOXX 600 & S&P 500\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "stoxx_px = fetch_prices_yahoo(TICKER_STOXX_600, start_date, end_date)\n",
    "spx_px = fetch_prices_yahoo(TICKER_SP500, start_date, end_date)\n",
    "\n",
    "print(\"STOXX 600 price series:\", stoxx_px.shape, \"rows\")\n",
    "print(\"S&P 500 price series:\", spx_px.shape, \"rows\")\n",
    "\n",
    "display(stoxx_px.to_frame().tail())\n",
    "display(spx_px.to_frame().tail())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a1ff46",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "            # ------------------------------------------------------------------\n",
    "            # 2ï¸âƒ£ Validate & clean (if processors are available)\n",
    "            # ------------------------------------------------------------------\n",
    "\n",
    "            if validator is not None and cleaner is not None:\n",
    "                print(\"Using project validator/cleaner pipeline.\\n\")\n",
    "\"\n",
    "                # Validate raw series\n",
    "\"\n",
    "                stoxx_report = validator.validate_price_series(stoxx_px, symbol=\"STOXX_600\")\n",
    "\"\n",
    "                spx_report = validator.validate_price_series(spx_px, symbol=\"SP500\")\n",
    "\"\n",
    "\n",
    "\"\n",
    "                print(\"STOXX validation issues:\")\n",
    "\"\n",
    "                for issue in stoxx_report.issues:\n",
    "\"\n",
    "                    print(\" -\", issue)\n",
    "\"\n",
    "\n",
    "\"\n",
    "                print(\"\\nS&P 500 validation issues:\")\n",
    "\"\n",
    "                for issue in spx_report.issues:\n",
    "\"\n",
    "                    print(\" -\", issue)\n",
    "\"\n",
    "\n",
    "\"\n",
    "                # Clean series\n",
    "\"\n",
    "                stoxx_clean, stoxx_clean_report = cleaner.clean_price_series(\n",
    "\"\n",
    "                    stoxx_px,\n",
    "\"\n",
    "                    symbol=\"STOXX_600\",\n",
    "\"\n",
    "                    validation_report=stoxx_report,\n",
    "\"\n",
    "                )\n",
    "\"\n",
    "                spx_clean, spx_clean_report = cleaner.clean_price_series(\n",
    "\"\n",
    "                    spx_px,\n",
    "\"\n",
    "                    symbol=\"SP500\",\n",
    "\"\n",
    "                    validation_report=spx_report,\n",
    "\"\n",
    "                )\n",
    "\"\n",
    "            else:\n",
    "\"\n",
    "                print(\"[WARN] validator/cleaner not available â€“ using raw series as 'clean'.\")\n",
    "\"\n",
    "                stoxx_clean, spx_clean = stoxx_px.copy(), spx_px.copy()\n",
    "\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16fbf13",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "            # ------------------------------------------------------------------\n",
    "            # 3ï¸âƒ£ Compute daily returns & relative performance\n",
    "            # ------------------------------------------------------------------\n",
    "\n",
    "            def compute_returns(prices: pd.Series) -> pd.Series:\n",
    "                rets = prices.pct_change().replace([np.inf, -np.inf], np.nan)\n",
    "                return rets\n",
    "\n",
    "            stoxx_ret = compute_returns(stoxx_clean).rename(\"STOXX_600_ret\")\n",
    "            spx_ret = compute_returns(spx_clean).rename(\"SP500_ret\")\n",
    "\n",
    "            # Align on common index\n",
    "            ret_df = pd.concat([stoxx_ret, spx_ret], axis=1).dropna()\n",
    "\n",
    "            # Relative performance = STOXX cumulative / SPX cumulative - 1\n",
    "            stoxx_cum = (1 + ret_df[\"STOXX_600_ret\"]).cumprod()\n",
    "            spx_cum = (1 + ret_df[\"SP500_ret\"]).cumprod()\n",
    "            rel_perf = (stoxx_cum / spx_cum - 1).rename(\"EU_vs_US_relative\")\n",
    "\n",
    "            print(\"Returns DataFrame shape:\", ret_df.shape)\n",
    "\"\n",
    "            display(ret_df.tail())\n",
    "\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426bef53",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 4ï¸âƒ£ Basic risk & performance statistics\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "def summarize_returns(r: pd.Series, name: str) -> pd.Series:\n",
    "    ann_factor = 252\n",
    "    mean_daily = r.mean()\n",
    "    vol_daily = r.std()\n",
    "    ann_return = (1 + mean_daily) ** ann_factor - 1\n",
    "    ann_vol = vol_daily * np.sqrt(ann_factor)\n",
    "    sharpe = ann_return / ann_vol if ann_vol != 0 else np.nan\n",
    "    max_dd = ((1 + r).cumprod() / (1 + r).cumprod().cummax() - 1).min()\n",
    "    return pd.Series(\n",
    "        {\n",
    "            \"mean_daily\": mean_daily,\n",
    "            \"vol_daily\": vol_daily,\n",
    "            \"ann_return\": ann_return,\n",
    "            \"ann_vol\": ann_vol,\n",
    "            \"sharpe\": sharpe,\n",
    "            \"max_drawdown\": max_dd,\n",
    "        },\n",
    "        name=name,\n",
    "    )\n",
    "\n",
    "stoxx_stats = summarize_returns(stoxx_ret.dropna(), \"STOXX_600\")\n",
    "spx_stats = summarize_returns(spx_ret.dropna(), \"SP500\")\n",
    "\n",
    "stats_df = pd.concat([stoxx_stats, spx_stats], axis=1)\n",
    "print(\"ðŸ“Š Risk & performance summary:\")\n",
    "display(stats_df.T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48930286",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 5ï¸âƒ£ Visualizations â€“ Indexed performance & relative performance\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(12, 8), sharex=True)\n",
    "\n",
    "# Indexed performance\n",
    "base_val = 100.0\n",
    "stoxx_indexed = (1 + stoxx_ret.dropna()).cumprod() * base_val\n",
    "spx_indexed = (1 + spx_ret.dropna()).cumprod() * base_val\n",
    "\n",
    "axes[0].plot(stoxx_indexed.index, stoxx_indexed, label=\"STOXX 600\", linewidth=2)\n",
    "axes[0].plot(spx_indexed.index, spx_indexed, label=\"S&P 500\", linewidth=2)\n",
    "axes[0].set_title(\"Indexed Performance (base 100)\")\n",
    "axes[0].set_ylabel(\"Index Level\")\n",
    "axes[0].legend()\n",
    "\n",
    "# Relative performance (%)\n",
    "axes[1].plot(rel_perf.index, rel_perf * 100, color=\"tab:green\", linewidth=2)\n",
    "axes[1].axhline(0, color=\"black\", linestyle=\"--\", linewidth=1)\n",
    "axes[1].set_title(\"Relative Performance: Europe vs US (STOXX / S&P - 1)\")\n",
    "axes[1].set_ylabel(\"EU vs US (%)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dceae5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ------------------------------------------------------------------\n",
    "# 6ï¸âƒ£ Build multi-asset panel (for sectors / baskets later)\n",
    "# ------------------------------------------------------------------\n",
    "\n",
    "if aggregator is not None:\n",
    "    print(\"Using DataAggregator to build a simple panel with STOXX and S&P.\")\n",
    "\n",
    "    series_dict = {\n",
    "        \"STOXX_600\": stoxx_clean,\n",
    "        \"SP500\": spx_clean,\n",
    "    }\n",
    "    panel, panel_report = aggregator.build_panel_from_series_dict(\n",
    "        series_dict,\n",
    "        name=\"eu_vs_us_prices\",\n",
    "        normalize_returns=False,\n",
    "    )\n",
    "\n",
    "    print(\"Panel shape:\", panel.shape)\n",
    "    print(\"Aggregation steps:\")\n",
    "    for step in panel_report.steps:\n",
    "        print(f\" - {step.action.value}: {step.description}\")\n",
    "else:\n",
    "    print(\"[INFO] aggregator not available â€“ skip panel construction for now.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90079010",
   "metadata": {},
   "source": [
    "## âœ… Next Steps\n",
    "\n",
    "You now have:\n",
    "\n",
    "- Cleaned STOXX 600 and S&P 500 price and return series\n",
    "- Basic risk and performance metrics\n",
    "- A relative performance series (EU vs US)\n",
    "- (Optionally) a canonical price panel via `DataAggregator`\n",
    "\n",
    "From here you can:\n",
    "\n",
    "- Add **macro data** (FRED / ECB) and join with market series\n",
    "- Explore **sector / basket** performance by building additional panels\n",
    "- Feed these series into your **signal generator** and **backtest engine**\n",
    "- Validate that the input data used by the Streamlit dashboard is clean and robust\n",
    "\n",
    "> Tip: Duplicate this notebook as `02_signal_development.ipynb` to prototype\n",
    "> new momentum/value/macro signals on top of these series."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
